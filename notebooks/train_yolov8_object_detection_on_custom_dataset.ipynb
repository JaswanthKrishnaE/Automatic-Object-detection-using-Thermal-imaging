{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe9vkEvFABbN"
      },
      "source": [
        "[![Roboflow Notebooks](https://ik.imagekit.io/roboflow/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)\n",
        "\n",
        "# How to Train YOLOv8 Object Detection on a Custom Dataset\n",
        "\n",
        "---\n",
        "\n",
        "[![Roboflow](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/roboflow-blogpost.svg)](https://blog.roboflow.com/how-to-train-yolov8-on-a-custom-dataset)\n",
        "[![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/wuZtUMEiKWY)\n",
        "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/ultralytics/ultralytics)\n",
        "\n",
        "Ultralytics YOLOv8 is the latest version of the YOLO (You Only Look Once) object detection and image segmentation model developed by Ultralytics. The YOLOv8 model is designed to be fast, accurate, and easy to use, making it an excellent choice for a wide range of object detection and image segmentation tasks. It can be trained on large datasets and is capable of running on a variety of hardware platforms, from CPUs to GPUs.\n",
        "\n",
        "## ⚠️ Disclaimer\n",
        "\n",
        "YOLOv8 is still under heavy development. Breaking changes are being introduced almost weekly. We strive to make our YOLOv8 notebooks work with the latest version of the library. Last tests took place on **27.01.2023** with version **YOLOv8.0.20**.\n",
        "\n",
        "If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.\n",
        "\n",
        "## Accompanying Blog Post\n",
        "\n",
        "We recommend that you follow along in this notebook while reading the blog post on how to train YOLOv8 Object Detection, concurrently.\n",
        "\n",
        "## Pro Tip: Use GPU Acceleration\n",
        "\n",
        "If you are running this notebook in Google Colab, navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`. This will ensure your notebook uses a GPU, which will significantly speed up model training times.\n",
        "\n",
        "## Steps in this Tutorial\n",
        "\n",
        "In this tutorial, we are going to cover:\n",
        "\n",
        "- Before you start\n",
        "- Install YOLOv8\n",
        "- CLI Basics\n",
        "- Inference with Pre-trained COCO Model\n",
        "- Roboflow Universe\n",
        "- Preparing a custom dataset\n",
        "- Custom Training\n",
        "- Validate Custom Model\n",
        "- Inference with Custom Model\n",
        "\n",
        "**Let's begin!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyRdDYkqAKN4"
      },
      "source": [
        "## Before you start\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cDtxLIBHgQ",
        "outputId": "c8ce07f6-a854-447b-b752-7192dafc858b"
      },
      "outputs": [],
      "source": [
        "# !nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjpPg4mGKc1v",
        "outputId": "a646b1f8-1cc8-42d8-b309-175ba26faab4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d:\\softwares\\Codes\\GIT HUB\\Automatic-Object-detection-using-Thermal-imaging\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C3EO_2zNChu"
      },
      "source": [
        "## Install YOLOv8\n",
        "\n",
        "⚠️ YOLOv8 is still under heavy development. Breaking changes are being introduced almost weekly. We strive to make our YOLOv8 notebooks work with the latest version of the library. Last tests took place on **27.01.2023** with version **YOLOv8.0.20**.\n",
        "\n",
        "If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.\n",
        "\n",
        "YOLOv8 can be installed in two ways - from the source and via pip. This is because it is the first iteration of YOLO to have an official package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdSMcABDNKW-",
        "outputId": "f536188c-b95c-4a0d-de5c-5966f35b6005"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.58  Python-3.11.2 torch-2.0.0+cpu CPU\n",
            "Setup complete  (12 CPUs, 15.8 GB RAM, 127.3/931.4 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# Pip install method (recommended)\n",
        "\n",
        "# !pip install ultralytics==8.0.20\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VOEYrlBoP9-E"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnnZSm5OQfPQ"
      },
      "source": [
        "## CLI Basics "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K33S7zlkQku0"
      },
      "source": [
        "If you want to train, validate or run inference on models and don't need to make any modifications to the code, using YOLO command line interface is the easiest way to get started. Read more about CLI in [Ultralytics YOLO Docs](https://v8docs.ultralytics.com/cli/).\n",
        "\n",
        "```\n",
        "yolo task=detect    mode=train    model=yolov8n.yaml      args...\n",
        "          classify       predict        yolov8n-cls.yaml  args...\n",
        "          segment        val            yolov8n-seg.yaml  args...\n",
        "                         export         yolov8n.pt        format=onnx  args...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvkqhbs5Rcd7",
        "outputId": "4e630c8f-55fa-4bb1-cc80-f8f6a5c54a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/cfg/__init__.py\", line 230, in entrypoint\n",
            "    model = YOLO(model)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/model.py\", line 60, in __init__\n",
            "    {'.pt': self._load, '.yaml': self._new}[suffix](model)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/yolo/engine/model.py\", line 90, in _load\n",
            "    self.model, self.ckpt = attempt_load_one_weight(weights)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/nn/tasks.py\", line 384, in attempt_load_one_weight\n",
            "    ckpt = torch_safe_load(weight)  # load ckpt\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/ultralytics/nn/tasks.py\", line 332, in torch_safe_load\n",
            "    return torch.load(file, map_location='cpu')  # load\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/serialization.py\", line 771, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/serialization.py\", line 270, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/serialization.py\", line 251, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/runs/detect/train/weights/best.pt'\n"
          ]
        }
      ],
      "source": [
        "!yolo export model=/content/runs/detect/train/weights/best.pt format=torchscript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5RGYA6sPgEd"
      },
      "source": [
        "## Inference with Pre-trained COCO Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaE1kLS8R4CV"
      },
      "source": [
        "`yolo mode=predict` runs YOLOv8 inference on a variety of sources, downloading models automatically from the latest YOLOv8 release, and saving results to `runs/predict`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSd93ZJzZZKt",
        "outputId": "8aed431b-10f7-4dec-c563-81ed882de533"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for +: 'NoneType' and 'str'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# !mkdir {HOME}/datasets\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# %cd {HOME}/datasets\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[39m# !pip install roboflow\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mroboflow\u001b[39;00m \u001b[39mimport\u001b[39;00m Roboflow\n\u001b[0;32m      7\u001b[0m \u001b[39m# rf = Roboflow(api_key=\"D90rVo7ahGyBHqpqtBIH\")\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m# project = rf.workspace(\"thermal-imaging-0hwfw\").project(\"flir-data-set\")\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m# dataset = project.version(14).download(\"yolov8\")\u001b[39;00m\n",
            "File \u001b[1;32md:\\softwares\\Codes\\GIT HUB\\Automatic-Object-detection-using-Thermal-imaging\\BTPenv\\Lib\\site-packages\\roboflow\\__init__.py:9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparse\u001b[39;00m \u001b[39mimport\u001b[39;00m urlparse\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mroboflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m API_URL, APP_URL, DEMO_KEYS, load_roboflow_api_key\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mroboflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproject\u001b[39;00m \u001b[39mimport\u001b[39;00m Project\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mroboflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mworkspace\u001b[39;00m \u001b[39mimport\u001b[39;00m Workspace\n",
            "File \u001b[1;32md:\\softwares\\Codes\\GIT HUB\\Automatic-Object-detection-using-Thermal-imaging\\BTPenv\\Lib\\site-packages\\roboflow\\config.py:44\u001b[0m\n\u001b[0;32m     41\u001b[0m SEMANTIC_SEGMENTATION_MODEL \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSemanticSegmentationModel\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     42\u001b[0m PREDICTION_OBJECT \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mPREDICTION_OBJECT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPrediction\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m API_URL \u001b[39m=\u001b[39m get_conditional_configuration_variable(\u001b[39m\"\u001b[39;49m\u001b[39mAPI_URL\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mhttps://api.roboflow.com\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     45\u001b[0m APP_URL \u001b[39m=\u001b[39m get_conditional_configuration_variable(\u001b[39m\"\u001b[39m\u001b[39mAPP_URL\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhttps://app.roboflow.com\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m UNIVERSE_URL \u001b[39m=\u001b[39m get_conditional_configuration_variable(\n\u001b[0;32m     47\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mUNIVERSE_URL\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhttps://universe.roboflow.com\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m )\n",
            "File \u001b[1;32md:\\softwares\\Codes\\GIT HUB\\Automatic-Object-detection-using-Thermal-imaging\\BTPenv\\Lib\\site-packages\\roboflow\\config.py:20\u001b[0m, in \u001b[0;36mget_conditional_configuration_variable\u001b[1;34m(key, default)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Retrieves the configuration variable conditionally.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m    ##1. check if variable is in environment\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m    ##2. check if variable is in config file\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39m    string: The value of the conditional configuration variable.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# default configuration location\u001b[39;00m\n\u001b[0;32m     18\u001b[0m conf_location \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\n\u001b[0;32m     19\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mROBOFLOW_CONFIG_DIR\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m---> 20\u001b[0m     default\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39;49mgetenv(\u001b[39m\"\u001b[39;49m\u001b[39mHOME\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m/.config/roboflow/config.json\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[39m# read config file for roboflow if logged in from python or CLI\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(conf_location):\n",
            "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'str'"
          ]
        }
      ],
      "source": [
        "# !mkdir {HOME}/datasets\n",
        "# %cd {HOME}/datasets\n",
        "\n",
        "# !pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"D90rVo7ahGyBHqpqtBIH\")\n",
        "project = rf.workspace(\"thermal-imaging-0hwfw\").project(\"flir-data-set\")\n",
        "dataset = project.version(14).download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUjFBKKqXa-u"
      },
      "source": [
        "## Custom Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2YkphuiaE7_",
        "outputId": "f139362f-8e9e-4965-b3b3-63c41d298191"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"D:\\softwares\\Codes\\GIT HUB\\Automatic-Object-detection-using-Thermal-imaging\\BTPenv\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
            "  File \"D:\\softwares\\Codes\\GIT HUB\\Automatic-Object-detection-using-Thermal-imaging\\BTPenv\\Lib\\site-packages\\ultralytics\\yolo\\cfg\\__init__.py\", line 256, in entrypoint\n",
            "    raise SyntaxError(f\"'{colorstr('red', 'bold', a)}' is a valid YOLO argument but is missing an '=' sign \"\n",
            "SyntaxError: '\u001b[31m\u001b[1mdata\u001b[0m' is a valid YOLO argument but is missing an '=' sign to set its value, i.e. try 'data=None'\n",
            "\n",
            "    Arguments received: ['yolo', 'task=detect', 'mode=train', 'model=yolov8s.pt', \"data='datasets\\\\FLIR\", 'data', \"set.v21-raw-images.yolov8\\\\data.yaml'\", 'epochs=20']. Ultralytics 'yolo' commands use the following syntax:\n",
            "\n",
            "        yolo TASK MODE ARGS\n",
            "\n",
            "        Where   TASK (optional) is one of [detect, segment, classify]\n",
            "                MODE (required) is one of [train, val, predict, export, track]\n",
            "                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n",
            "                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n",
            "\n",
            "    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n",
            "        yolo train data=coco128.yaml model=yolov8n.pt epochs=10 lr0=0.01\n",
            "\n",
            "    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n",
            "        yolo predict model=yolov8n-seg.pt source='https://youtu.be/Zgi9g1ksQHc' imgsz=320\n",
            "\n",
            "    3. Val a pretrained detection model at batch-size 1 and image size 640:\n",
            "        yolo val model=yolov8n.pt data=coco128.yaml batch=1 imgsz=640\n",
            "\n",
            "    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n",
            "        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n",
            "\n",
            "    5. Run special commands:\n",
            "        yolo help\n",
            "        yolo checks\n",
            "        yolo version\n",
            "        yolo settings\n",
            "        yolo copy-cfg\n",
            "        yolo cfg\n",
            "\n",
            "    Docs: https://docs.ultralytics.com\n",
            "    Community: https://community.ultralytics.com\n",
            "    GitHub: https://github.com/ultralytics/ultralytics\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "# %cd {HOME}\n",
        "\n",
        "!yolo task=detect mode=train model=yolov8s.pt data='datasets\\FLIR data set.v21-raw-images.yolov8\\data.yaml' epochs=20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MScstfHhArr",
        "outputId": "823c61d6-376a-4875-e069-59b458b94297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ls: cannot access '{HOME}/runs/detect/train/': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!ls {HOME}/runs/detect/train/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_J35i8Ofhjxa"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "Image(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-urTWUkhRmn"
      },
      "outputs": [],
      "source": [
        "# %cd {HOME}\n",
        "# Image(filename=f'{HOME}/runs/detect/train/results.png', width=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HI4nADCCj3F5"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "Image(filename=f'{HOME}/runs/detect/train/val_batch0_pred.jpg', width=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ODk1VTlevxn"
      },
      "source": [
        "## Validate Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpyuwrNlXc1P"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "!yolo task=detect mode=val model={HOME}/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4eASbcWkQBq"
      },
      "source": [
        "## Inference with Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wjc1ctZykYuf"
      },
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "!yolo task=detect mode=predict model={HOME}/runs/detect/train/weights/best.pt conf=0.25 source={dataset.location}/test/images save=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEYIo95n-I0S"
      },
      "source": [
        "**NOTE:** Let's take a look at few results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbVjEtPAkz3j"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for image_path in glob.glob(f'{HOME}/runs/detect/predict3/*.jpg')[:3]:\n",
        "      display(Image(filename=image_path, width=600))\n",
        "      print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0tsVilOCPyq"
      },
      "source": [
        "## Deploy model on Roboflow\n",
        "\n",
        "Once you have finished training your YOLOv8 model, you’ll have a set of trained weights ready for use. These weights will be in the `/runs/detect/train/weights/best.pt` folder of your project. You can upload your model weights to Roboflow Deploy to use your trained weights on our infinitely scalable infrastructure.\n",
        "\n",
        "The `.deploy()` function in the [Roboflow pip package](https://docs.roboflow.com/python) now supports uploading YOLOv8 weights.\n",
        "\n",
        "To upload model weights, add the following code to the “Inference with Custom Model” section in the aforementioned notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EhBAJ2gCPZh"
      },
      "outputs": [],
      "source": [
        "project.version(dataset.version).deploy(model_type=\"yolov8\", model_path=f\"{HOME}/runs/detect/train/\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "python SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gb8eaG4qPUQa"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AXcJ21lgPYKa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.Detect                [80, [64, 128, 256]]          \n",
            "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
            "100%|██████████| 6.23M/6.23M [00:02<00:00, 2.63MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = YOLO('yolov8n.yaml')  # build a new model from scratch\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.58  Python-3.11.2 torch-2.0.0+cpu CPU\n",
            "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=datasets/flir/data.yaml, epochs=20, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=d:\\softwares\\Codes\\GIT HUB\\AUTOMATIC-DETECTION-OF-MANGOS-USING-THERMAL-IMAGING\\runs\\detect\\train3\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Dataset 'datasets/flir/data.yaml' error  \nDataset 'datasets/flir/data.yaml' images not found , missing paths ['D:\\\\softwares\\\\Codes\\\\GIT HUB\\\\datasets\\\\datasets\\\\flir\\\\valid\\\\images']",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[1;32md:\\softwares\\Codes\\GIT HUB\\Automatic-Object-detection-using-Thermal-imaging\\BTPenv\\Lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py:123\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.yaml\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mtask \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mdetect\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msegment\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m check_det_dataset(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mdata)\n\u001b[0;32m    124\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39myaml_file\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata:\n",
            "File \u001b[1;32md:\\softwares\\Codes\\GIT HUB\\Automatic-Object-detection-using-Thermal-imaging\\BTPenv\\Lib\\site-packages\\ultralytics\\yolo\\data\\utils.py:248\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[1;34m(dataset, autodownload)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 248\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(m)\n\u001b[0;32m    249\u001b[0m t \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: \nDataset 'datasets/flir/data.yaml' images not found ⚠️, missing paths ['D:\\\\softwares\\\\Codes\\\\GIT HUB\\\\datasets\\\\datasets\\\\flir\\\\valid\\\\images']",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain(data\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdatasets/flir/data.yaml\u001b[39;49m\u001b[39m'\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)  \u001b[39m# train the model\u001b[39;00m\n",
            "File \u001b[1;32md:\\softwares\\Codes\\GIT HUB\\Automatic-Object-detection-using-Thermal-imaging\\BTPenv\\Lib\\site-packages\\ultralytics\\yolo\\engine\\model.py:324\u001b[0m, in \u001b[0;36mYOLO.train\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    321\u001b[0m     overrides[\u001b[39m'\u001b[39m\u001b[39mresume\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mckpt_path\n\u001b[0;32m    323\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask \u001b[39m=\u001b[39m overrides\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask\n\u001b[1;32m--> 324\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m TASK_MAP[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask][\u001b[39m1\u001b[39;49m](overrides\u001b[39m=\u001b[39;49moverrides)\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m overrides\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mresume\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# manually set model only if not resuming\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mget_model(weights\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mckpt \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, cfg\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39myaml)\n",
            "File \u001b[1;32md:\\softwares\\Codes\\GIT HUB\\Automatic-Object-detection-using-Thermal-imaging\\BTPenv\\Lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py:127\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39myaml_file\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(emojis(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataset \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdata\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m error ❌ \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainset, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtestset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n\u001b[0;32m    130\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mema \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Dataset 'datasets/flir/data.yaml' error  \nDataset 'datasets/flir/data.yaml' images not found , missing paths ['D:\\\\softwares\\\\Codes\\\\GIT HUB\\\\datasets\\\\datasets\\\\flir\\\\valid\\\\images']"
          ]
        }
      ],
      "source": [
        "results = model.train(data='datasets/flir/data.yaml', epochs=20)  # train the model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
